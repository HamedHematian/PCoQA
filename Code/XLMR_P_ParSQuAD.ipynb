{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBX9WDkFwsjL"
      },
      "source": [
        "# Libraries & Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuaR7fKTp_7y"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install transformers\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL9GKLsIm1BB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! wget https://github.com/BigData-IsfahanUni/ParSQuAD/blob/main/Dataset/ParSQuAD.zip?raw=true -O ParSQuAD.zip\n",
        "! unzip ParSQuAD.zip\n",
        "! rm -r examples/train\n",
        "! rm -r examples/eval\n",
        "! rm -r features/train\n",
        "! rm -r features/eval\n",
        "! mkdir -p examples/train\n",
        "! mkdir -p examples/eval\n",
        "! mkdir -p features/train\n",
        "! mkdir -p features/eval\n",
        "! rm -r HistConcat/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tW5BR5tldmp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "import pickle\n",
        "import unicodedata\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "import transformers\n",
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "from transformers import BertModel, BertForQuestionAnswering, AutoTokenizer, AutoModel\n",
        "import os\n",
        "from collections import defaultdict, namedtuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import AdamW, Adam, RMSprop\n",
        "from copy import deepcopy\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "790d8dd198a548d88ca2527d70411076",
            "b00bfdeca66d41ecaba08ce7436bc6d7",
            "31f552eeed0f44948241eca545eded40",
            "060aa73680084433886afd50facc856c",
            "9d8d4f5ea97d4bc7907d906e2f729259",
            "ec2953d57f574c628274a94a4d20e320",
            "168304b1551948ad92a2cc8c83552214",
            "1ceb119bac8f45df88992dbdf499a8e5",
            "73e9976e291b449e8f100e7f2a578e90",
            "3359b8f8fb1e417694f31f62f022439a",
            "4b8199e545f445288d98305c066e5835",
            "373eb8730e9a41d98c56810076712c36",
            "bed50831ae824820b72c2cced954c224",
            "3aa00b01b0284d68b935a1f18163479c",
            "6024606625aa45738cd22fd722f48216",
            "693a9208aa6d4c36a14d667e7f814418",
            "746db496d2364065a656d70e2f9c4970",
            "2f40708d234646d4a035618d41e0a8df",
            "bcb37d2d5dc74a5ba2acf96bf01b3261",
            "d440b99bcbca4187a58049b4b56cad25",
            "5fb720863a29408b81f1288c643f17e3",
            "afa85f73129441a09676913584c65c20",
            "312670f27fd843b8a73fffc44d475e46",
            "e8ad7705350240fe9c52b9a938778c90",
            "b03fcc97fd3e40f985349db9e52418f8",
            "d7d20948aa0e45d8809a67d2337025ed",
            "bc7a9c59e362423dba1960d3e3215915",
            "cf53295e15dd46579fdb6339b006bb97",
            "a35e32d1275f49c8b2f18b3105408951",
            "e2b54b4ad7364403a5ccf39765862470",
            "083cb0ee42124ce9817a1f2426480472",
            "ed1a96eb18cb4bb8af37269b3f997985",
            "33f951f78fe3415daa6fa1989ab02a18",
            "e1a69555a32849ea95f8d2c50053a38c",
            "6c9f6dd3b0444d7cb5cfe321249fcf91",
            "4eba81eef0d042aa84d44e930dd42c7d",
            "dc76cd2bf6e04465affe3969f1d35355",
            "765c2e6bc0a345249e77fad58a90c7cb",
            "0f69d9838856420d8fdc6988a49a2f9c",
            "844c8f9125f24380b23a1b51db6312dc",
            "84a6113975674e0a8aca5533a6a23af9",
            "d2533c80dc7b4873ac93457344cf29ea",
            "39ec954988014439a0aa0870cb6f0bab",
            "676f08f9ad324ebba80c6be78f2292f0"
          ]
        },
        "id": "JcX1yR4GnPO9",
        "outputId": "5fcccda8-35b0-4243-ccc0-fb96fbcde3c6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "790d8dd198a548d88ca2527d70411076",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "373eb8730e9a41d98c56810076712c36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "312670f27fd843b8a73fffc44d475e46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1a69555a32849ea95f8d2c50053a38c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def read_file(filename):\n",
        "  with open(filename, 'r') as f:\n",
        "    return json.load(f)\n",
        "\n",
        "def load_data(filename):\n",
        "  with open(filename, 'rb') as f:\n",
        "    x = pickle.load(f)\n",
        "  return x\n",
        "\n",
        "def save_data(data, filename):\n",
        "    with open(filename, \"wb\") as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "train_path = 'ParSQuAD/ParSQuAD-automatic-train.json'\n",
        "eval_path = 'ParSQuAD/ParSQuAD-automatic-dev.json'\n",
        "model_path_or_name = 'xlm-roberta-base'\n",
        "\n",
        "# load data\n",
        "train_data = read_file(train_path)\n",
        "eval_data = read_file(eval_path)\n",
        "\n",
        "# load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path_or_name)\n",
        "model = AutoModel.from_pretrained(model_path_or_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klvWCqdsSmEB"
      },
      "source": [
        "# Official Evaluation Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vBDDFWFSrMc"
      },
      "outputs": [],
      "source": [
        "import json, string, re\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "\n",
        "def is_overlapping(x1, x2, y1, y2):\n",
        "  return max(x1, y1) <= min(x2, y2)\n",
        "\n",
        "def normalize_answer(s):\n",
        "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "  def remove_articles(text):\n",
        "    return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "  def white_space_fix(text):\n",
        "    return ' '.join(text.split())\n",
        "  def remove_punc(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    return ''.join(ch for ch in text if ch not in exclude)\n",
        "  def lower(text):\n",
        "    return text.lower()\n",
        "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "  prediction_tokens = normalize_answer(prediction).split()\n",
        "  ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "  common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "  num_same = sum(common.values())\n",
        "  if num_same == 0:\n",
        "    return 0\n",
        "  precision = 1.0 * num_same / len(prediction_tokens)\n",
        "  recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "  f1 = (2 * precision * recall) / (precision + recall)\n",
        "  return f1\n",
        "\n",
        "def compute_span_overlap(pred_span, gt_span, text):\n",
        "  if gt_span == 'غیرقابل‌پاسخ':\n",
        "    if pred_span == 'غیرقابل‌پاسخ':\n",
        "      return 'Exact match', 1.0\n",
        "    return 'No overlap', 0.\n",
        "  fscore = f1_score(pred_span, gt_span)\n",
        "  pred_start = text.find(pred_span)\n",
        "  gt_start = text.find(gt_span)\n",
        "\n",
        "  if pred_start == -1 or gt_start == -1:\n",
        "    return 'Span indexing error', fscore\n",
        "\n",
        "  pred_end = pred_start + len(pred_span)\n",
        "  gt_end = gt_start + len(gt_span)\n",
        "\n",
        "  fscore = f1_score(pred_span, gt_span)\n",
        "  overlap = is_overlapping(pred_start, pred_end, gt_start, gt_end)\n",
        "\n",
        "  if exact_match_score(pred_span, gt_span):\n",
        "    return 'Exact match', fscore\n",
        "  if overlap:\n",
        "    return 'Partial overlap', fscore\n",
        "  else:\n",
        "    return 'No overlap', fscore\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "  return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "def display_counter(title, c, c2=None):\n",
        "  print(title)\n",
        "  for key, _ in c.most_common():\n",
        "    if c2:\n",
        "      print('%s: %d / %d, %.1f%%, F1: %.1f' % (\n",
        "        key, c[key], sum(c.values()), c[key] * 100. / sum(c.values()), sum(c2[key]) * 100. / len(c2[key])))\n",
        "    else:\n",
        "      print('%s: %d / %d, %.1f%%' % (key, c[key], sum(c.values()), c[key] * 100. / sum(c.values())))\n",
        "\n",
        "def leave_one_out_max(prediction, ground_truths, article):\n",
        "  if len(ground_truths) == 1:\n",
        "    return metric_max_over_ground_truths(prediction, ground_truths, article)[1]\n",
        "  else:\n",
        "    t_f1 = []\n",
        "    # leave out one ref every time\n",
        "    for i in range(len(ground_truths)):\n",
        "      idxes = list(range(len(ground_truths)))\n",
        "      idxes.pop(i)\n",
        "      refs = [ground_truths[z] for z in idxes]\n",
        "      t_f1.append(metric_max_over_ground_truths(prediction, refs, article)[1])\n",
        "  return 1.0 * sum(t_f1) / len(t_f1)\n",
        "\n",
        "\n",
        "def metric_max_over_ground_truths(prediction, ground_truths, article):\n",
        "  scores_for_ground_truths = []\n",
        "  for ground_truth in ground_truths:\n",
        "    score = compute_span_overlap(prediction, ground_truth, article)\n",
        "    scores_for_ground_truths.append(score)\n",
        "  return max(scores_for_ground_truths, key=lambda x: x[1])\n",
        "\n",
        "\n",
        "def handle_cannot(refs):\n",
        "  num_cannot = 0\n",
        "  num_spans = 0\n",
        "  for ref in refs:\n",
        "    if ref == 'غیرقابل‌پاسخ':\n",
        "      num_cannot += 1\n",
        "    else:\n",
        "      num_spans += 1\n",
        "  if num_cannot >= num_spans:\n",
        "    refs = ['CANNOTANSWER']\n",
        "  else:\n",
        "    refs = [x for x in refs if x != 'غیرقابل‌پاسخ']\n",
        "  return refs\n",
        "\n",
        "\n",
        "def leave_one_out(refs):\n",
        "  if len(refs) == 1:\n",
        "    return 1.\n",
        "  splits = []\n",
        "  for r in refs:\n",
        "    splits.append(r.split())\n",
        "  t_f1 = 0.0\n",
        "  for i in range(len(refs)):\n",
        "    m_f1 = 0\n",
        "    for j in range(len(refs)):\n",
        "      if i == j:\n",
        "        continue\n",
        "      f1_ij = f1_score(refs[i], refs[j])\n",
        "      if f1_ij > m_f1:\n",
        "        m_f1 = f1_ij\n",
        "    t_f1 += m_f1\n",
        "  return t_f1 / len(refs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def eval_fn(val_results, model_results, verbose):\n",
        "  span_overlap_stats = Counter()\n",
        "  sentence_overlap = 0.\n",
        "  para_overlap = 0.\n",
        "  total_qs = 0.\n",
        "  f1_stats = defaultdict(list)\n",
        "  unfiltered_f1s = []\n",
        "  total_dials = 0.\n",
        "  unanswerables = []\n",
        "  for p in val_results:\n",
        "    for par in p['paragraphs']:\n",
        "      did = par['id']\n",
        "      qa_list = par['qas']\n",
        "      good_dial = 1.\n",
        "      for qa in qa_list:\n",
        "        q_idx = qa['id']\n",
        "        val_spans = [anss['text'] for anss in qa['answers']]\n",
        "        val_spans = handle_cannot(val_spans)\n",
        "        hf1 = leave_one_out(val_spans)\n",
        "\n",
        "        if did not in model_results or q_idx not in model_results[did]:\n",
        "          # print(did, q_idx, 'no prediction for this dialogue id')\n",
        "          good_dial = 0\n",
        "          f1_stats['NO ANSWER'].append(0.0)\n",
        "          if val_spans == ['غیرقابل‌پاسخ']:\n",
        "            unanswerables.append(0.0)\n",
        "          total_qs += 1\n",
        "          unfiltered_f1s.append(0.0)\n",
        "          if hf1 >= .4:\n",
        "            human_f1.append(hf1)\n",
        "          continue\n",
        "\n",
        "        pred_span, pred_yesno, pred_followup = model_results[did][q_idx]\n",
        "\n",
        "        max_overlap, _ = metric_max_over_ground_truths( \\\n",
        "          pred_span, val_spans, par['context'])\n",
        "        max_f1 = leave_one_out_max( \\\n",
        "          pred_span, val_spans, par['context'])\n",
        "        unfiltered_f1s.append(max_f1)\n",
        "\n",
        "        # dont eval on low agreement instances\n",
        "        if hf1 < .4:\n",
        "          continue\n",
        "\n",
        "        human_f1.append(hf1)\n",
        "\n",
        "        if val_spans == ['غیرقابل‌پاسخ']:\n",
        "          unanswerables.append(max_f1)\n",
        "        if verbose:\n",
        "          print(\"-\" * 20)\n",
        "          print(pred_span)\n",
        "          print(val_spans)\n",
        "          print(max_f1)\n",
        "          print(\"-\" * 20)\n",
        "        if max_f1 >= hf1:\n",
        "          HEQ += 1.\n",
        "        else:\n",
        "          good_dial = 0.\n",
        "        span_overlap_stats[max_overlap] += 1\n",
        "        f1_stats[max_overlap].append(max_f1)\n",
        "        total_qs += 1.\n",
        "      DHEQ += good_dial\n",
        "      total_dials += 1\n",
        "\n",
        "\n",
        "  DHEQ_score = 100.0 * DHEQ / total_dials\n",
        "  HEQ_score = 100.0 * HEQ / total_qs\n",
        "  all_f1s = sum(f1_stats.values(), [])\n",
        "  overall_f1 = 100.0 * sum(all_f1s) / len(all_f1s)\n",
        "  unfiltered_f1 = 100.0 * sum(unfiltered_f1s) / len(unfiltered_f1s)\n",
        "  unanswerable_score = (100.0 * sum(unanswerables) / len(unanswerables))\n",
        "  metric_json = {\"unfiltered_f1\": unfiltered_f1, \"f1\": overall_f1, \"HEQ\": HEQ_score, \"DHEQ\": DHEQ_score, \"yes/no\": yesno_score, \"followup\": followup_score, \"unanswerable_acc\": unanswerable_score}\n",
        "  if verbose:\n",
        "    print(\"=======================\")\n",
        "    display_counter('Overlap Stats', span_overlap_stats, f1_stats)\n",
        "  print(\"=======================\")\n",
        "  print('Overall F1: %.1f' % overall_f1)\n",
        "  with open('val_report.txt', 'a') as f:\n",
        "    f.write('Overall F1: %.1f' % overall_f1)\n",
        "\n",
        "  print('Unfiltered F1 ({0:d} questions): {1:.1f}'.format(len(unfiltered_f1s), unfiltered_f1))\n",
        "  print('Accuracy On Unanswerable Questions: {0:.1f} %% ({1:d} questions)'.format(unanswerable_score, len(unanswerables)))\n",
        "  print('Human F1: %.1f' % (100.0 * sum(human_f1) / len(human_f1)))\n",
        "  print('Model F1 >= Human F1 (Questions): %d / %d, %.1f%%' % (HEQ, total_qs, 100.0 * HEQ / total_qs))\n",
        "  print('Model F1 >= Human F1 (Dialogs): %d / %d, %.1f%%' % (DHEQ, total_dials, 100.0 * DHEQ / total_dials))\n",
        "  print(\"=======================\")\n",
        "  output_string = 'Overall F1: %.1f\\n' % overall_f1\n",
        "  output_string += 'Yes/No Accuracy : %.1f\\n' % yesno_score\n",
        "  output_string += 'Followup Accuracy : %.1f\\n' % followup_score\n",
        "  output_string += 'Unfiltered F1 ({0:d} questions): {1:.1f}\\n'.format(len(unfiltered_f1s), unfiltered_f1)\n",
        "  output_string += 'Accuracy On Unanswerable Questions: {0:.1f} %% ({1:d} questions)\\n'.format(unanswerable_score, len(unanswerables))\n",
        "  output_string += 'Human F1: %.1f\\n' % (100.0 * sum(human_f1) / len(human_f1))\n",
        "  output_string += 'Model F1 >= Human F1 (Questions): %d / %d, %.1f%%\\n' % (HEQ, total_qs, 100.0 * HEQ / total_qs)\n",
        "  output_string += 'Model F1 >= Human F1 (Dialogs): %d / %d, %.1f%%' % (DHEQ, total_dials, 100.0 * DHEQ / total_dials)\n",
        "\n",
        "  # save_prediction(epoch, train_step, output_string)\n",
        "\n",
        "  return metric_json\n",
        "\n",
        "def run_eval():\n",
        "  new_eval_data = dict()\n",
        "  for data in eval_data['data']:\n",
        "    for d in data['paragraphs']:\n",
        "      for qa in d['qas']:\n",
        "        new_eval_data[qa['id']] = dict()\n",
        "        new_eval_data[qa['id']]['answers'] = [a['text'] for a in qa['answers']]\n",
        "        new_eval_data[qa['id']]['context'] = d['context']\n",
        "  f1s = []\n",
        "  for qid, model_answer in eval_p.answers.items():\n",
        "    orig_answers = new_eval_data[qid]['answers']\n",
        "    context = new_eval_data[qid]['context']\n",
        "    f1s_ = []\n",
        "    for orig_answer in orig_answers:\n",
        "      f1 = compute_span_overlap(model_answer, orig_answer, context)[1]\n",
        "      f1s_.append(f1)\n",
        "    f1s.append(max(f1s_))\n",
        "  f1_score_ = sum(f1s) / len(f1s)\n",
        "  print('f1 is', f1_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_-QjOxXznHw"
      },
      "outputs": [],
      "source": [
        "train_data = read_file('ParSQuAD/ParSQuAD-automatic-train.json')\n",
        "eval_data = read_file('ParSQuAD/ParSQuAD-automatic-dev.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nQ8QqO9rfpT"
      },
      "outputs": [],
      "source": [
        "# eval_data['data'][0]['paragraphs'][0]['qas']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ8K618EwydR"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ2HnsMKnFId"
      },
      "outputs": [],
      "source": [
        "class QA_DATA:\n",
        "\n",
        "  def __init__(self,\n",
        "               question,\n",
        "               context,\n",
        "               answer,\n",
        "               qid,\n",
        "               q_num,\n",
        "               answer_start,\n",
        "               answer_end,\n",
        "               is_answerable):\n",
        "\n",
        "    self.question = question\n",
        "    self.context = context\n",
        "    self.answer = answer\n",
        "    self.qid = qid\n",
        "    self.q_num = q_num\n",
        "    self.answer_start = answer_start\n",
        "    self.answer_end = answer_end\n",
        "    self.is_answerable = is_answerable\n",
        "    self.cleaned_context = None\n",
        "    self.answer = self.answer['text']\n",
        "    self.cleaned_answer = answer\n",
        "    self.cleaned_context = context\n",
        "\n",
        "  def __repr__(self):\n",
        "    repr = ''\n",
        "    repr += 'context -> ' + self.context[:100] + '\\n'\n",
        "    repr += 'question ->' + self.question + '\\n'\n",
        "    repr += 'question id ->' + str(self.qid) + '\\n'\n",
        "    repr += 'turn_number ->' + str(self.turn_number) + '\\n'\n",
        "    repr += 'answer ->' + self.answers[0]['text'] + '\\n'\n",
        "    return repr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbyqY9tE1S7-"
      },
      "outputs": [],
      "source": [
        "class Feature:\n",
        "\n",
        "  def __init__(self,\n",
        "               qid,\n",
        "               question_part,\n",
        "               input_ids,\n",
        "               attention_mask,\n",
        "               offset_mappings,\n",
        "               max_context_dict,\n",
        "               start,\n",
        "               end,\n",
        "               is_answerable,\n",
        "               context,\n",
        "               cleaned_context,\n",
        "               context_start,\n",
        "               context_end,\n",
        "               example_start_char,\n",
        "               example_end_char,\n",
        "               example_answer):\n",
        "\n",
        "    self.qid = qid\n",
        "    self.question_part = question_part\n",
        "    self.input_ids = input_ids\n",
        "    self.attention_mask = attention_mask\n",
        "    self.offset_mappings = offset_mappings\n",
        "    self.max_context_dict = max_context_dict\n",
        "    self.start = start\n",
        "    self.end = end\n",
        "    self.is_answerable = is_answerable\n",
        "    self.context = context\n",
        "    self.cleaned_context = cleaned_context\n",
        "    self.context_start = context_start\n",
        "    self.context_end = context_end\n",
        "    self.example_start_char = example_start_char\n",
        "    self.example_end_char = example_end_char\n",
        "    self.example_answer = example_answer\n",
        "\n",
        "  def __repr__(self):\n",
        "    repr = ''\n",
        "    repr += 'qid --> ' + str(self.qid) + '\\n'\n",
        "    repr += 'quesion part --> ' + str(self.question_part) + '\\n'\n",
        "    repr += 'answer part --> ' + str(self.start) + ' ' + str(self.end) + '\\n'\n",
        "    return repr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfqAND5NOWgD"
      },
      "source": [
        "# Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCTy21ProL3j"
      },
      "outputs": [],
      "source": [
        "def make_examples(datas, data_type):\n",
        "  examples = []\n",
        "  each_file_size = 5000\n",
        "  example_file_index = 0\n",
        "  data_dir = f'examples/{data_type}/'\n",
        "\n",
        "\n",
        "  for data_id, data in tqdm(enumerate(datas['data'])):\n",
        "\n",
        "    for par in data['paragraphs']:\n",
        "\n",
        "        qas = par['qas']\n",
        "        context = par['context'] + ' غیرقابل‌پاسخ'\n",
        "\n",
        "        for q_num, qa in enumerate(qas):\n",
        "          qid = qa['id']\n",
        "          question = qa['question']\n",
        "\n",
        "          is_answerable = False if qa['is_impossible'] == True else True\n",
        "\n",
        "          answer = qa['answers']\n",
        "          if len(answer) != 0:\n",
        "            answer = answer[0]\n",
        "          else:\n",
        "            continue\n",
        "\n",
        "          if qa['is_impossible'] == True:\n",
        "            print('yes')\n",
        "\n",
        "          if not is_answerable:\n",
        "            print(answer['text'])\n",
        "            ans_start = context.find('غیرقابل‌پاسخ')\n",
        "            answer_ = {\n",
        "                'text': 'غیرقابل‌پاسخ',\n",
        "                'start': ans_start,\n",
        "                'end': ans_start + len('غیرقابل‌پاسخ')\n",
        "          }\n",
        "          else:\n",
        "            answer_ = {\n",
        "                'text': answer['text'],\n",
        "                'start': answer['answer_start'],\n",
        "                'end': answer['answer_start'] + len(answer['text'])\n",
        "            }\n",
        "\n",
        "          qa_example = QA_DATA(question=question,\n",
        "                                context=context,\n",
        "                                answer=answer_,\n",
        "                                qid=qid,\n",
        "                                q_num=q_num,\n",
        "                                answer_start=answer_['start'],\n",
        "                                answer_end=answer_['end'],\n",
        "                                is_answerable=is_answerable)\n",
        "\n",
        "          examples.append(qa_example)\n",
        "\n",
        "          if len(examples) % each_file_size == 0:\n",
        "            filename = f'{data_type}_examples_' + str(example_file_index) + '.bin'\n",
        "            save_data(examples, os.path.join(data_dir, filename))\n",
        "            example_file_index += 1\n",
        "            examples = []\n",
        "\n",
        "  if examples != []:\n",
        "    filename = f'{data_type}_examples_' + str(example_file_index) + '.bin'\n",
        "    save_data(examples, os.path.join(data_dir, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA1ICM6HOZJ-"
      },
      "source": [
        "# Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G07euhk_P_Ri"
      },
      "outputs": [],
      "source": [
        "def make_features(data_type):\n",
        "  data_dir = f'examples/{data_type}/'\n",
        "  example_files = os.listdir(data_dir)\n",
        "  example_files = [os.path.join(data_dir, example_file) for example_file in example_files]\n",
        "  features_list = []\n",
        "  features_dir = f'features/{data_type}/'\n",
        "  current_file_index = 0\n",
        "  max_history_to_consider = 1\n",
        "\n",
        "  for file_index, filename in enumerate(example_files):\n",
        "    examples = load_data(filename)\n",
        "    for example in tqdm(examples, leave=False, position=0):\n",
        "      example_features = []\n",
        "      concatenated_question = []\n",
        "\n",
        "\n",
        "      # append current question to concatenated question\n",
        "      concatenated_question.append(example.question)\n",
        "\n",
        "      # make string out of concatenated question\n",
        "      concatenated_question = ' '.join(concatenated_question)\n",
        "\n",
        "      # tokenize current feature\n",
        "      text_tokens = tokenizer(\n",
        "          concatenated_question,\n",
        "          example.cleaned_context,\n",
        "          max_length=model.config.max_position_embeddings - 2,\n",
        "          padding='max_length',\n",
        "          truncation='only_second',\n",
        "          return_overflowing_tokens=True,\n",
        "          return_offsets_mapping=True,\n",
        "          stride=128)\n",
        "\n",
        "      # find start and end of context\n",
        "      for idx in range(len(text_tokens['input_ids'])):\n",
        "        found_start = False\n",
        "        found_end = False\n",
        "        context_start = 0\n",
        "        cintext_end = 511\n",
        "        max_context_dict = {}\n",
        "\n",
        "        for token_idx, token in enumerate(text_tokens['offset_mapping'][idx][1:]):\n",
        "          if token[0] == 0 and token[1] == 0:\n",
        "            context_start = token_idx + 3\n",
        "            break\n",
        "\n",
        "        for token_idx, token in enumerate(text_tokens['offset_mapping'][idx][context_start:]):\n",
        "          if token[0] == 0 and token[1] == 0:\n",
        "            context_end = token_idx + context_start - 1\n",
        "            break\n",
        "\n",
        "        chunk_offset_mapping = text_tokens['offset_mapping'][idx]\n",
        "        for context_idx, data in enumerate(chunk_offset_mapping[context_start: context_end + 1]):\n",
        "          max_context_dict[f'({data[0]},{data[1]})'] = min(context_idx, context_end - context_idx) + (context_end - context_start + 1) * .01\n",
        "\n",
        "        # find and mark current question answer\n",
        "        marker_ids = np.zeros(shape=(model.config.max_position_embeddings,), dtype=np.int64)\n",
        "        last_token = None\n",
        "        for token_idx, token in enumerate(chunk_offset_mapping[context_start: context_end + 1]):\n",
        "          if token[0] == example.cleaned_answer['start'] and not found_start:\n",
        "            found_start = True\n",
        "            start = token_idx + context_start\n",
        "\n",
        "          elif last_token and last_token[0] < example.cleaned_answer['start'] and token[0] > example.cleaned_answer['start']:\n",
        "            found_start = True\n",
        "            start = (token_idx - 1) + context_start\n",
        "\n",
        "          if token[1] == example.cleaned_answer['end'] and not found_end:\n",
        "            found_end = True\n",
        "            end = token_idx + context_start\n",
        "\n",
        "          elif last_token and last_token[1] < example.cleaned_answer['end'] and token[1] > example.cleaned_answer['end'] and last_token:\n",
        "            found_end = True\n",
        "            end = token_idx + context_start\n",
        "          last_token = token\n",
        "\n",
        "        # add feature to features list\n",
        "        if found_start and found_end and end < start:\n",
        "          assert False, 'start and end do not match'\n",
        "\n",
        "        # since there is no prediction we throw the example out (only when training)\n",
        "        if ((not found_start) or (not found_end)) and data_type == 'train':\n",
        "          continue\n",
        "\n",
        "        # if ((not found_start) or (not found_end)) and data_type == 'train':\n",
        "        #   continue\n",
        "        #   start, end = 0, 0\n",
        "        #   if example.is_answerable == False:\n",
        "        #     print(example.answers[0]['text'])\n",
        "\n",
        "        # plausibility check\n",
        "        if found_start or found_end:\n",
        "          answer = example.cleaned_answer['text'].strip()\n",
        "          generated_answer = example.cleaned_context[chunk_offset_mapping[start][0]: chunk_offset_mapping[end][1]]\n",
        "          if answer.find(generated_answer) == -1:\n",
        "            pass\n",
        "\n",
        "        # mark history answers\n",
        "\n",
        "        example_features.append(Feature(example.qid,\n",
        "                                          idx,\n",
        "                                          text_tokens['input_ids'][idx],\n",
        "                                          text_tokens['attention_mask'][idx],\n",
        "                                          text_tokens['offset_mapping'][idx],\n",
        "                                          max_context_dict,\n",
        "                                          start,\n",
        "                                          end,\n",
        "                                          example.is_answerable,\n",
        "                                          example.context,\n",
        "                                          example.cleaned_context,\n",
        "                                          context_start,\n",
        "                                          context_end,\n",
        "                                          example.answer_start,\n",
        "                                          example.answer_end,\n",
        "                                          example.answer))\n",
        "      # create max context mask\n",
        "      for feature_1 in example_features:\n",
        "        max_context_mask = {}\n",
        "        for key in list(feature_1.max_context_dict.keys()):\n",
        "          max_context_mask[key] = True\n",
        "          for feature_2 in example_features:\n",
        "            if key in feature_2.max_context_dict:\n",
        "              if feature_1.max_context_dict[key] < feature_2.max_context_dict[key]:\n",
        "                max_context_mask[key] = False\n",
        "        feature_1.max_context_mask = max_context_mask\n",
        "\n",
        "        found_start = found_end = False\n",
        "        start_mask = end_mask = 0\n",
        "        # now compute span mask\n",
        "        for key_idx, (key, value) in enumerate(feature_1.max_context_mask.items()):\n",
        "          if key_idx == 0 and value:\n",
        "            found_start = True\n",
        "          elif value and not found_start:\n",
        "            start_mask = key_idx\n",
        "            found_start = True\n",
        "          elif not value and found_start and not found_end:\n",
        "            end_mask = key_idx\n",
        "            found_end = True\n",
        "          elif key_idx == len(feature_1.max_context_mask) - 1 and value and not found_end:\n",
        "            end_mask = key_idx + 1\n",
        "        feature_1.mask_span = [context_start + start_mask, context_start + end_mask]\n",
        "      features_list.extend(example_features)\n",
        "\n",
        "    filename = f'{data_type}_features_' + str(file_index) + '.bin'\n",
        "    save_data(features_list, os.path.join(features_dir, filename))\n",
        "    features_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGL-bxcJPDTj",
        "outputId": "3776c369-7d66-4347-aaff-c41a6baf10ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "442it [00:01, 247.11it/s]\n",
            "35it [00:00, 42.27it/s]\n"
          ]
        }
      ],
      "source": [
        "make_examples(train_data, 'train')\n",
        "make_examples(eval_data, 'eval')\n",
        "make_features('train')\n",
        "make_features('eval')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxFLOtgbwibI"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxJWQlfxcXUP"
      },
      "outputs": [],
      "source": [
        "class DataManager:\n",
        "\n",
        "  def __init__(self, current_file, current_index, data_dir, batch_size, shuffle=True):\n",
        "    self.files = sorted(os.listdir(data_dir), key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
        "    self.files = list(map(lambda x: os.path.join(data_dir, x), self.files))\n",
        "    self.shuffle = shuffle\n",
        "    self.data_len = 0\n",
        "    for filename in self.files:\n",
        "      self.data_len += len(load_data(filename))\n",
        "    self.batch_size = batch_size\n",
        "    self.reset_datamanager(current_file, current_index)\n",
        "\n",
        "  def reset_datamanager(self, current_file_index, current_index):\n",
        "    self.current_index = current_index\n",
        "    self.current_file_index = current_file_index\n",
        "    self.features = self.load_data_file(self.files[self.current_file_index])\n",
        "\n",
        "  def load_data_file(self, filename):\n",
        "    if self.shuffle:\n",
        "      data = load_data(filename)\n",
        "      random.shuffle(data)\n",
        "      return data\n",
        "    else:\n",
        "      return load_data(filename)\n",
        "\n",
        "  def next(self):\n",
        "    temp = self.features[self.current_index:self.current_index + self.batch_size]\n",
        "    self.temp = temp\n",
        "    self.current_index += self.batch_size\n",
        "    if self.current_index >= len(self.features):\n",
        "      self.current_index = 0\n",
        "      self.current_file_index += 1\n",
        "      if self.current_file_index == len(self.files):\n",
        "        self.reset_datamanager(current_file_index=0, current_index=0)\n",
        "        return temp, True\n",
        "      else:\n",
        "        self.features = self.load_data_file(self.files[self.current_file_index])\n",
        "    return temp, False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snSdz65TdB11"
      },
      "outputs": [],
      "source": [
        "class DataLoader:\n",
        "\n",
        "  def __init__(self, current_file, current_index, batch_size, shuffle=True, training=True):\n",
        "    data_type = 'train' if training else 'eval'\n",
        "    self.batch_size = batch_size\n",
        "    self.data_manager = DataManager(current_file, current_index, f'features/{data_type}/', batch_size, shuffle)\n",
        "\n",
        "  def __iter__(self):\n",
        "    self.stop_iteration = False\n",
        "    return self\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(self.data_manager.data_len // self.batch_size)\n",
        "\n",
        "  def reset_dataloader(self, current_file, current_index):\n",
        "    self.data_manager.reset_datamanager(current_file, current_index)\n",
        "\n",
        "  def features_2_tensor(self, features):\n",
        "    x = dict()\n",
        "    x['input_ids'] = torch.LongTensor([feature.input_ids for feature in features])\n",
        "    x['attention_mask'] = torch.LongTensor([feature.attention_mask for feature in features])\n",
        "    #x['token_type_ids'] = torch.LongTensor([feature.token_type_ids for feature in features])\n",
        "    x['start_positions'] = torch.cat([torch.tensor([feature.start]) for feature in features]).view(-1)\n",
        "    x['end_positions'] = torch.cat([torch.tensor([feature.end]) for feature in features]).view(-1)\n",
        "    x['features'] = features\n",
        "    return x\n",
        "\n",
        "  def __next__(self):\n",
        "    if self.stop_iteration:\n",
        "      raise StopIteration\n",
        "    features, self.stop_iteration = self.data_manager.next()\n",
        "    return self.features_2_tensor(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xP75pmjbOGW"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxfai3OuiuzP"
      },
      "outputs": [],
      "source": [
        "feature_output = namedtuple(\n",
        "    'feature_output',\n",
        "        ['start_logit', 'end_logit', 'feature'])\n",
        "\n",
        "PrelimPrediction = namedtuple(\n",
        "    \"PrelimPrediction\",\n",
        "        [\"feature_index\", \"start_index\", \"end_index\", \"start_logit\", \"end_logit\", \"qid\"]\n",
        "    )\n",
        "\n",
        "NbestPrediction = namedtuple(\n",
        "    \"NbestPrediction\", [\"text\", \"start_logit\", \"end_logit\"]\n",
        ")\n",
        "\n",
        "Answer = namedtuple(\n",
        "    'Answer', ['qid', 'answer']\n",
        ")\n",
        "\n",
        "def to_numpy(tensor):\n",
        "  return tensor.detach().cpu().numpy()\n",
        "\n",
        "class EvalProcessOutput:\n",
        "  def __init__(self, n_best_size=4, answer_max_len=40, answerability_threshold=0.0):\n",
        "    self.answers = defaultdict(list)\n",
        "    self.examples_output = []\n",
        "    self.n_best_size = n_best_size\n",
        "    self.answer_max_len = answer_max_len\n",
        "    self.answerability_threshold = answerability_threshold\n",
        "    self.ps = []\n",
        "\n",
        "\n",
        "  def process_feature_output(self, start_logits, end_logits, features):\n",
        "    for start_logit, end_logit, feature in zip(start_logits, end_logits, features):\n",
        "      self.examples_output.append(\n",
        "          feature_output(start_logit, end_logit, feature)\n",
        "      )\n",
        "\n",
        "  def stack_features(self):\n",
        "    examples_list = defaultdict(list)\n",
        "    for feature_out in self.examples_output:\n",
        "      examples_list[feature_out.feature.qid].append(feature_out)\n",
        "    return examples_list\n",
        "\n",
        "\n",
        "  def process_output(self):\n",
        "    self.extract_answers()\n",
        "    self.get_predictions()\n",
        "\n",
        "  def get_predictions(self):\n",
        "    dialogs = defaultdict(list)\n",
        "    self.dialogs_answers = defaultdict(list)\n",
        "    for example_qid, answer in self.answers.items():\n",
        "      dialog_id = example_qid\n",
        "      dialogs[dialog_id].append(Answer(example_qid, answer))\n",
        "    self.dialogs_answers = dialogs\n",
        "\n",
        "\n",
        "  def extract_answers(self):\n",
        "    examples_list = self.stack_features()\n",
        "    for example_qid, example in examples_list.items():\n",
        "      null_score = np.inf\n",
        "      prelim_predictions = []\n",
        "      self.example = example\n",
        "      for feature_index, feature_output in enumerate(example):\n",
        "        feature_null_score = feature_output.start_logit[0] + feature_output.end_logit[0]\n",
        "\n",
        "        if feature_null_score < null_score:\n",
        "          null_score = feature_null_score\n",
        "          null_feature_index = feature_index\n",
        "          null_start_logit = feature_output.start_logit[0]\n",
        "          null_end_logit = feature_output.end_logit[0]\n",
        "\n",
        "        start_indexes = self.get_best_indexes(feature_output.start_logit)\n",
        "        end_indexes = self.get_best_indexes(feature_output.end_logit)\n",
        "\n",
        "        for start_index in start_indexes:\n",
        "          for end_index in end_indexes:\n",
        "            if start_index > feature_output.feature.context_end:\n",
        "              continue\n",
        "            # if end_index > feature_output.feature.context_end:\n",
        "            #   continue\n",
        "            # if start_index < feature_output.feature.context_start:\n",
        "            #   continue\n",
        "            if end_index < feature_output.feature.context_start:\n",
        "              continue\n",
        "            if start_index < feature_output.feature.mask_span[0]:\n",
        "              continue\n",
        "            if end_index - start_index + 1 > self.answer_max_len:\n",
        "              continue\n",
        "            if end_index <= start_index:\n",
        "              continue\n",
        "\n",
        "            prelim_predictions.append(\n",
        "                PrelimPrediction(\n",
        "                  feature_index=feature_index,\n",
        "                  start_index=start_index,\n",
        "                  end_index=end_index,\n",
        "                  start_logit=feature_output.start_logit[start_index],\n",
        "                  end_logit=feature_output.end_logit[end_index],\n",
        "                  qid=example_qid\n",
        "            )\n",
        "                )\n",
        "      # append a null one for handling CANNOTANSWER\n",
        "      prelim_predictions.append(\n",
        "        PrelimPrediction(\n",
        "          feature_index=null_feature_index,\n",
        "          start_index=0,\n",
        "          end_index=0,\n",
        "          start_logit=null_start_logit,\n",
        "          end_logit=null_end_logit,\n",
        "          qid=example_qid\n",
        "      )\n",
        "        )\n",
        "      prelim_predictions = sorted(prelim_predictions, key=lambda x: (x.start_logit + x.end_logit), reverse=True)\n",
        "      self.t = prelim_predictions\n",
        "      # print(ff)\n",
        "      best_pred = prelim_predictions[0]\n",
        "      is_answerable = null_score - (best_pred.start_logit + best_pred.end_logit) <= self.answerability_threshold\n",
        "      if is_answerable:\n",
        "        feature = example[best_pred.feature_index].feature\n",
        "        start_char = feature.offset_mappings[best_pred.start_index][0]\n",
        "        end_char = feature.offset_mappings[best_pred.end_index][1]\n",
        "        answer = feature.cleaned_context[start_char: end_char + 1]\n",
        "        # answer = self.improve_answer_quality(answer)\n",
        "      else:\n",
        "        answer = 'غیرقابل‌پاسخ'\n",
        "\n",
        "      self.answers[example_qid] = answer\n",
        "\n",
        "\n",
        "  def get_best_indexes(self, logits):\n",
        "    index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
        "    best_indexes = []\n",
        "    for i in range(len(index_and_score)):\n",
        "        if i >= self.n_best_size:\n",
        "            break\n",
        "        best_indexes.append(index_and_score[i][0])\n",
        "    return best_indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sysx5f2M6zJ4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z6-77pg5Mbj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjXRvscl5Me-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5wuU_qq5Mih"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PCI0rY35Mlj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RMu9bqfTGXb"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MH9inpN7THfx"
      },
      "outputs": [],
      "source": [
        "class BertHAE(nn.Module):\n",
        "\n",
        "  def __init__(self, bert, device):\n",
        "    super(BertHAE, self).__init__()\n",
        "    self.transformer = bert\n",
        "    self.start_end_head = nn.Linear(self.transformer.config.hidden_size, 2)\n",
        "    nn.init.normal_(self.start_end_head.weight, mean=.0, std=.02)\n",
        "    self.device = device\n",
        "\n",
        "  def forward(self, x):\n",
        "    for key in x:\n",
        "      x[key] = x[key].to(device)\n",
        "    # transformer output\n",
        "    transformer_output = self.transformer(**x)\n",
        "    start_end_logits = self.start_end_head(transformer_output.last_hidden_state)\n",
        "    start_logits, end_logits = start_end_logits.split(1, dim=-1)\n",
        "    start_logits = start_logits.squeeze(-1)\n",
        "    end_logits = end_logits.squeeze(-1)\n",
        "    return start_logits, end_logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVEJYM1Z4drU"
      },
      "source": [
        "# Saving Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpESpkmR6CAj",
        "outputId": "bc64a4ac-8ad7-4216-acaa-d3f47f2f81d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "crated saved dir\n"
          ]
        }
      ],
      "source": [
        "drive_prefix = 'drive/MyDrive/XLMR_P_ParSQuAD/'\n",
        "drive_checkpoint_dir = 'Checkpoint/'\n",
        "drive_log_dir = 'Log/'\n",
        "checkpoint_dir = os.path.join(drive_prefix, drive_checkpoint_dir)\n",
        "log_dir = os.path.join(drive_prefix, drive_log_dir)\n",
        "\n",
        "meta_log_file = os.path.join(drive_prefix, drive_log_dir, 'test.txt')\n",
        "prediction_file_prefix = os.path.join(drive_prefix, drive_log_dir, 'prediction_')\n",
        "loss_log_file = os.path.join(drive_prefix, drive_log_dir, 'loss.txt')\n",
        "mean_f1_file = os.path.join(drive_prefix, drive_log_dir, 'mean_f1.txt')\n",
        "\n",
        "if not os.path.exists(drive_prefix):\n",
        "  os.mkdir(drive_prefix)\n",
        "  print('crated saved dir')\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "  os.mkdir(checkpoint_dir)\n",
        "if not os.path.exists(log_dir):\n",
        "  os.mkdir(log_dir)\n",
        "\n",
        "with open(meta_log_file, 'w') as f:\n",
        "  pass\n",
        "# check if drive is accessible\n",
        "try:\n",
        "   with open(os.path.join(drive_prefix, drive_log_dir, 'test.txt'), 'r') as f:\n",
        "      pass\n",
        "except:\n",
        "  print('No Access to Drive')\n",
        "  exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bU70_bq6CZO",
        "outputId": "c9999f06-5a60-4fac-eddd-7bf8423da93a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'drive/MyDrive/checkpoint_1_0_0': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! cp drive/MyDrive/checkpoint_1_0_0 HistConcat/Checkpoint/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S1TjgAc4gNp",
        "outputId": "f8b43d86-0c01-4643-cd82-2d759a7c6921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No checkpoint found, training from begining\n"
          ]
        }
      ],
      "source": [
        "def print_loss(loss_collection, epoch, step):\n",
        "  txt = f'EPOCH [{epoch + 1}/{epochs}] | STEP [{step}/{int(len(train_dataloader) / accumulation_steps)}] | Loss {round(sum(loss_collection) / len(loss_collection), 4)}'\n",
        "  print(txt)\n",
        "\n",
        "def save_loss(loss_collection, epoch, step):\n",
        "  txt = f'EPOCH [{epoch + 1}/{epochs}] | STEP [{step}/{int(len(train_dataloader) / accumulation_steps)}] | Loss {round(sum(loss_collection) / len(loss_collection), 4)}'\n",
        "  with open(loss_log_file, 'a') as f:\n",
        "    f.write(txt)\n",
        "    f.write('\\n')\n",
        "\n",
        "\n",
        "\n",
        "# check the checkpoints drive\n",
        "checkpoint_files = os.listdir(os.path.join(drive_prefix, drive_checkpoint_dir))\n",
        "if len(checkpoint_files) == 0:\n",
        "  checkpoint_available = False\n",
        "  print('No checkpoint found, training from begining')\n",
        "else:\n",
        "  checkpoint_available = True\n",
        "  assert len(checkpoint_files) >= 1, 'Checkpoints are messed up'\n",
        "\n",
        "if checkpoint_available:\n",
        "  current_checkpoint = sorted(checkpoint_files, key=lambda x: [int(x.split('_')[1]), int(x.split('_')[2]), int(x.split('_')[3])])[-1]\n",
        "  print('checkpoints to load ', current_checkpoint)\n",
        "  current_checkpoint = os.path.join(drive_prefix, drive_checkpoint_dir, current_checkpoint)\n",
        "\n",
        "\n",
        "def save_prediction(epoch, step, prediction_log):\n",
        "  with open(os.path.join(drive_prefix, drive_log_dir, 'prediction.txt'), 'a') as f:\n",
        "    f.write(f'--------- EPOCH {epoch} STEP {step} ---------\\n')\n",
        "    f.write(prediction_log)\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "\n",
        "def save_checkpoint(epoch, current_file, current_index):\n",
        "  filename_prefix = os.path.join(drive_prefix, drive_checkpoint_dir, f'checkpoint_{epoch}_{current_file}_{current_index}')\n",
        "  checkpoint_config = {\n",
        "  'epoch': epoch,\n",
        "  'step': train_step,\n",
        "  'optimizer_dict': optimizer.state_dict(),\n",
        "  'scheduler_dict': scheduler.state_dict(),\n",
        "  'model_dict': berthae.state_dict(),\n",
        "  'train_current_file': current_file,\n",
        "  'train_current_index': current_index}\n",
        "  torch.save(checkpoint_config, filename_prefix)\n",
        "\n",
        "def load_checkpoint():\n",
        "    # models have been loaded before so no need to load them again\n",
        "    checkpoint_config = torch.load(current_checkpoint)\n",
        "    return (checkpoint_config['epoch'],\n",
        "            checkpoint_config['step'],\n",
        "            checkpoint_config['optimizer_dict'],\n",
        "            checkpoint_config['scheduler_dict'],\n",
        "            checkpoint_config['model_dict'],\n",
        "            checkpoint_config['train_current_file'],\n",
        "            checkpoint_config['train_current_index'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiS6rtcd3zDS"
      },
      "source": [
        "# Train loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XUAmIcT0wrk"
      },
      "outputs": [],
      "source": [
        "epochs = 0\n",
        "lr = 3e-5\n",
        "beta_1 = .9\n",
        "beta_2 = .999\n",
        "eps = 1e-6\n",
        "batch_size = 10\n",
        "accumulation_steps = 1\n",
        "accumulation_counter = 0\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "berthae = BertHAE(deepcopy(model), device).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "loss_collection = []\n",
        "train_dataloader = DataLoader(current_file=0, current_index=0, batch_size=batch_size, shuffle=True, training=True)\n",
        "eval_dataloader = DataLoader(current_file=0, current_index=0, batch_size=1, shuffle=False, training=False)\n",
        "each_step_log = 100\n",
        "start_epoch = 0\n",
        "start_step = 0\n",
        "current_file = 0\n",
        "current_index = 0\n",
        "\n",
        "\n",
        "optimization_steps = int(epochs * len(train_dataloader) / accumulation_steps)\n",
        "warmup_ratio = .1\n",
        "warmup_steps = int(optimization_steps * warmup_ratio)\n",
        "\n",
        "optimizer = AdamW(berthae.parameters(), lr=lr, betas=(beta_1,beta_2), eps=eps)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=optimization_steps)\n",
        "\n",
        "# laod checkpoint if available\n",
        "if checkpoint_available:\n",
        "  print('loading checkpoint')\n",
        "  start_epoch, start_step, optimizer_dict, scheduler_dict, berthae_dict, current_file, current_index = load_checkpoint()\n",
        "  # load state dicts\n",
        "  berthae.load_state_dict(berthae_dict)\n",
        "  optimizer.load_state_dict(optimizer_dict)\n",
        "  scheduler.load_state_dict(scheduler_dict)\n",
        "\n",
        "current_file_index_ = current_file\n",
        "train_dataloader.reset_dataloader(current_file, current_index)\n",
        "berthae.train()\n",
        "for epoch in range(start_epoch, epochs):\n",
        "  train_step = 0\n",
        "  acc_loss = 0\n",
        "  log_step = 0\n",
        "\n",
        "  for data in train_dataloader:\n",
        "    if train_dataloader.data_manager.current_file_index != current_file_index_:\n",
        "      current_file_index_ = train_dataloader.data_manager.current_file_index\n",
        "      print(current_file_index_)\n",
        "      print('-------------')\n",
        "      if int(current_file_index_) % 3 == 0 and current_file_index_ != current_file:\n",
        "        save_checkpoint(epoch, current_file_index_, 0)\n",
        "    start_positions = data.pop('start_positions').to(device)\n",
        "    end_positions = data.pop('end_positions').to(device)\n",
        "    features = data.pop('features')\n",
        "    start_logits, end_logits = berthae(data)\n",
        "    loss = (loss_fn(start_logits, start_positions) + loss_fn(end_logits, end_positions)) / 2\n",
        "    loss = loss / accumulation_steps\n",
        "    acc_loss += loss.item()\n",
        "    loss.backward()\n",
        "\n",
        "    if len(loss_collection) % each_step_log == 0 and len(loss_collection) != 0:\n",
        "      print_loss(loss_collection, epoch, log_step + 1)\n",
        "      save_loss(loss_collection, epoch, log_step + 1)\n",
        "      loss_collection = []\n",
        "\n",
        "\n",
        "    accumulation_counter += 1\n",
        "    if accumulation_counter % accumulation_steps == 0:\n",
        "      loss_collection.append(acc_loss)\n",
        "      acc_loss = 0\n",
        "      log_step += 1\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      optimizer.zero_grad()\n",
        "      torch.cuda.empty_cache()\n",
        "      accumulation_counter = 0\n",
        "\n",
        "    train_step += 1\n",
        "\n",
        "  save_checkpoint(epoch + 1, 0, 0)\n",
        "  berthae.eval()\n",
        "  print('-------------------- Evaluation --------------------')\n",
        "  eval_p = EvalProcessOutput()\n",
        "  with torch.no_grad():\n",
        "    for step, data in enumerate(eval_dataloader):\n",
        "      start_positions = data.pop('start_positions')\n",
        "      end_positions = data.pop('end_positions')\n",
        "      features = data.pop('features')\n",
        "      start_logits, end_logits = berthae(data)\n",
        "      eval_p.process_feature_output(to_numpy(start_logits),\n",
        "                                    to_numpy(end_logits),\n",
        "                                    features)\n",
        "\n",
        "  eval_p.process_output()\n",
        "  run_eval()\n",
        "  berthae.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-8kBK9-oy-A1"
      },
      "outputs": [],
      "source": [
        "  berthae.eval()\n",
        "  print('-------------------- Evaluation --------------------')\n",
        "  eval_p = EvalProcessOutput()\n",
        "  with torch.no_grad():\n",
        "    for step, data in enumerate(eval_dataloader):\n",
        "      start_positions = data.pop('start_positions')\n",
        "      end_positions = data.pop('end_positions')\n",
        "      features = data.pop('features')\n",
        "      start_logits, end_logits = berthae(data)\n",
        "      eval_p.process_feature_output(to_numpy(start_logits),\n",
        "                                    to_numpy(end_logits),\n",
        "                                    features)\n",
        "\n",
        "  eval_p.process_output()\n",
        "  run_eval()\n",
        "  berthae.train()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "gVEJYM1Z4drU"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "060aa73680084433886afd50facc856c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3359b8f8fb1e417694f31f62f022439a",
            "placeholder": "​",
            "style": "IPY_MODEL_4b8199e545f445288d98305c066e5835",
            "value": " 615/615 [00:00&lt;00:00, 7.66kB/s]"
          }
        },
        "083cb0ee42124ce9817a1f2426480472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f69d9838856420d8fdc6988a49a2f9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "168304b1551948ad92a2cc8c83552214": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ceb119bac8f45df88992dbdf499a8e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f40708d234646d4a035618d41e0a8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "312670f27fd843b8a73fffc44d475e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8ad7705350240fe9c52b9a938778c90",
              "IPY_MODEL_b03fcc97fd3e40f985349db9e52418f8",
              "IPY_MODEL_d7d20948aa0e45d8809a67d2337025ed"
            ],
            "layout": "IPY_MODEL_bc7a9c59e362423dba1960d3e3215915"
          }
        },
        "31f552eeed0f44948241eca545eded40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ceb119bac8f45df88992dbdf499a8e5",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73e9976e291b449e8f100e7f2a578e90",
            "value": 615
          }
        },
        "3359b8f8fb1e417694f31f62f022439a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33f951f78fe3415daa6fa1989ab02a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "373eb8730e9a41d98c56810076712c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bed50831ae824820b72c2cced954c224",
              "IPY_MODEL_3aa00b01b0284d68b935a1f18163479c",
              "IPY_MODEL_6024606625aa45738cd22fd722f48216"
            ],
            "layout": "IPY_MODEL_693a9208aa6d4c36a14d667e7f814418"
          }
        },
        "39ec954988014439a0aa0870cb6f0bab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa00b01b0284d68b935a1f18163479c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcb37d2d5dc74a5ba2acf96bf01b3261",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d440b99bcbca4187a58049b4b56cad25",
            "value": 5069051
          }
        },
        "4b8199e545f445288d98305c066e5835": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eba81eef0d042aa84d44e930dd42c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84a6113975674e0a8aca5533a6a23af9",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2533c80dc7b4873ac93457344cf29ea",
            "value": 1115567652
          }
        },
        "5fb720863a29408b81f1288c643f17e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6024606625aa45738cd22fd722f48216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fb720863a29408b81f1288c643f17e3",
            "placeholder": "​",
            "style": "IPY_MODEL_afa85f73129441a09676913584c65c20",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 15.1MB/s]"
          }
        },
        "676f08f9ad324ebba80c6be78f2292f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "693a9208aa6d4c36a14d667e7f814418": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c9f6dd3b0444d7cb5cfe321249fcf91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f69d9838856420d8fdc6988a49a2f9c",
            "placeholder": "​",
            "style": "IPY_MODEL_844c8f9125f24380b23a1b51db6312dc",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "73e9976e291b449e8f100e7f2a578e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "746db496d2364065a656d70e2f9c4970": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "765c2e6bc0a345249e77fad58a90c7cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "790d8dd198a548d88ca2527d70411076": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b00bfdeca66d41ecaba08ce7436bc6d7",
              "IPY_MODEL_31f552eeed0f44948241eca545eded40",
              "IPY_MODEL_060aa73680084433886afd50facc856c"
            ],
            "layout": "IPY_MODEL_9d8d4f5ea97d4bc7907d906e2f729259"
          }
        },
        "844c8f9125f24380b23a1b51db6312dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84a6113975674e0a8aca5533a6a23af9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d8d4f5ea97d4bc7907d906e2f729259": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a35e32d1275f49c8b2f18b3105408951": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afa85f73129441a09676913584c65c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b00bfdeca66d41ecaba08ce7436bc6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec2953d57f574c628274a94a4d20e320",
            "placeholder": "​",
            "style": "IPY_MODEL_168304b1551948ad92a2cc8c83552214",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "b03fcc97fd3e40f985349db9e52418f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b54b4ad7364403a5ccf39765862470",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_083cb0ee42124ce9817a1f2426480472",
            "value": 9096718
          }
        },
        "bc7a9c59e362423dba1960d3e3215915": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb37d2d5dc74a5ba2acf96bf01b3261": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed50831ae824820b72c2cced954c224": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_746db496d2364065a656d70e2f9c4970",
            "placeholder": "​",
            "style": "IPY_MODEL_2f40708d234646d4a035618d41e0a8df",
            "value": "Downloading (…)tencepiece.bpe.model: 100%"
          }
        },
        "cf53295e15dd46579fdb6339b006bb97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2533c80dc7b4873ac93457344cf29ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d440b99bcbca4187a58049b4b56cad25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7d20948aa0e45d8809a67d2337025ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed1a96eb18cb4bb8af37269b3f997985",
            "placeholder": "​",
            "style": "IPY_MODEL_33f951f78fe3415daa6fa1989ab02a18",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 46.4MB/s]"
          }
        },
        "dc76cd2bf6e04465affe3969f1d35355": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39ec954988014439a0aa0870cb6f0bab",
            "placeholder": "​",
            "style": "IPY_MODEL_676f08f9ad324ebba80c6be78f2292f0",
            "value": " 1.12G/1.12G [00:10&lt;00:00, 86.6MB/s]"
          }
        },
        "e1a69555a32849ea95f8d2c50053a38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c9f6dd3b0444d7cb5cfe321249fcf91",
              "IPY_MODEL_4eba81eef0d042aa84d44e930dd42c7d",
              "IPY_MODEL_dc76cd2bf6e04465affe3969f1d35355"
            ],
            "layout": "IPY_MODEL_765c2e6bc0a345249e77fad58a90c7cb"
          }
        },
        "e2b54b4ad7364403a5ccf39765862470": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8ad7705350240fe9c52b9a938778c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf53295e15dd46579fdb6339b006bb97",
            "placeholder": "​",
            "style": "IPY_MODEL_a35e32d1275f49c8b2f18b3105408951",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "ec2953d57f574c628274a94a4d20e320": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed1a96eb18cb4bb8af37269b3f997985": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}